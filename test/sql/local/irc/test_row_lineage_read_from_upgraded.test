# name: test/sql/local/irc/test_row_lineage_read_from_upgraded.test
# description: test integration with iceberg catalog read
# group: [irc]

require-env ICEBERG_SERVER_AVAILABLE

require avro

require parquet

require iceberg

require httpfs

# Do not ignore 'HTTP' error messages!
set ignore_error_messages

statement ok
set enable_logging=true

statement ok
set logging_level='debug'

statement ok
CREATE SECRET (
    TYPE S3,
    KEY_ID 'admin',
    SECRET 'password',
    ENDPOINT '127.0.0.1:9000',
    URL_STYLE 'path',
    USE_SSL 0
);

statement ok
ATTACH '' AS my_datalake (
    TYPE ICEBERG,
    CLIENT_ID 'admin',
    CLIENT_SECRET 'password',
    ENDPOINT 'http://127.0.0.1:8181'
);

loop i 0 7

statement ok
set variable snapshot${i} = (
	select {
		'snapshot_id': snapshot_id,
		'timestamp_ms': timestamp_ms
	} from iceberg_snapshots(
		my_datalake.default.row_lineage_test_upgraded_insert
	) order by timestamp_ms
	offset ${i} limit 1
);

endloop

# FIXME: the rowid should be NULL here, but we backfill row lineage for UPDATE purposes
# Insert rows 0-4
query IIII
select rowid, sequence_number, id, data from my_datalake.default.row_lineage_test_upgraded_insert AT (VERSION=>getvariable('snapshot0').snapshot_id) order by id;
----
0	1	1	a
1	1	2	b
2	1	3	c
3	1	4	d
4	1	5	e

# Update row_ids 1 and 3
query IIII
select rowid, sequence_number, id, data from my_datalake.default.row_lineage_test_upgraded_insert AT (VERSION=>getvariable('snapshot1').snapshot_id) order by id;
----
2	1	1	a
0	2	2	b_u1
3	1	3	c
1	2	4	d_u1
4	1	5	e

# Delete row_ids 2 and 4
query IIII
select rowid, sequence_number, id, data from my_datalake.default.row_lineage_test_upgraded_insert AT (VERSION=>getvariable('snapshot2').snapshot_id) order by id;
----
2	1	1	a
0	2	2	b_u1
1	2	4	d_u1

# Insert 2 new rows (because of various rewrites this starts with a much higher row_id)
query IIII
select rowid, sequence_number, id, data from my_datalake.default.row_lineage_test_upgraded_insert AT (VERSION=>getvariable('snapshot3').snapshot_id) order by id;
----
4	1	1	a
2	2	2	b_u1
3	2	4	d_u1
0	4	6	f
1	4	7	g

# UPDATE row_ids 0 and 11
query IIII
select rowid, sequence_number, id, data from my_datalake.default.row_lineage_test_upgraded_insert AT (VERSION=>getvariable('snapshot4').snapshot_id) order by id;
----
0	5	1	replaced
3	2	2	b_u1
4	2	4	d_u1
1	5	6	replaced
2	4	7	g

# DELETE row_id 12
query IIII
select rowid, sequence_number, id, data from my_datalake.default.row_lineage_test_upgraded_insert AT (VERSION=>getvariable('snapshot5').snapshot_id) order by id;
----
0	5	1	replaced
2	2	2	b_u1
3	2	4	d_u1
1	5	6	replaced

# INSERT row_id 16 (again, because of various rewrites this starts with a much higher row_id)
query IIII
select rowid, sequence_number, id, data from my_datalake.default.row_lineage_test_upgraded_insert AT (VERSION=>getvariable('snapshot6').snapshot_id) order by id;
----
1	5	1	replaced
3	2	2	b_u1
4	2	4	d_u1
2	5	6	replaced
0	7	7	g_new

# Latest state of the table, after upgrading to V3 and creating a new snapshot
query IIII
select rowid, sequence_number, id, data from my_datalake.default.row_lineage_test_upgraded_insert order by id;
----
3	5	1	replaced
1	8	2	replaced_again
6	2	4	d_u1
0	8	6	replaced_again
2	7	7	g_new
